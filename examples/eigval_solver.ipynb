{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "345ba182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"True\"\n",
    "# os.environ[\"JAX_DISABLE_JIT\"] = \"True\"\n",
    "# os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import sparse\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e173b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dim = 10\n",
    "key = jax.random.PRNGKey(0)\n",
    "density = 0.5\n",
    "wrkey1, wrkey2 = jax.random.split(key)\n",
    "spec_rad = 0.8\n",
    "\n",
    "N_nonzero = int(res_dim**2 * density)\n",
    "wr_indices = jax.random.choice(\n",
    "    wrkey1,\n",
    "    res_dim**2,\n",
    "    shape=(N_nonzero,),\n",
    ")\n",
    "wr_vals = jax.random.uniform(\n",
    "    wrkey2, shape=N_nonzero, minval=-1, maxval=1\n",
    ")\n",
    "wr = jnp.zeros(res_dim * res_dim)\n",
    "wr = wr.at[wr_indices].set(wr_vals)\n",
    "wr = wr.reshape(res_dim, res_dim)\n",
    "wr_dense = wr * (spec_rad / jnp.max(jnp.abs(jnp.linalg.eigvals(wr))))\n",
    "wr_sparse = sparse.BCOO.fromdense(wr_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a0d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def max_eig_arnoldi_np(A, tol=1e-12, max_iters=1000, seed=0):\n",
    "#     n = A.shape[0]\n",
    "#     np.random.seed(seed)\n",
    "#     b = np.random.rand(n)\n",
    "#     b = b / np.linalg.norm(b)\n",
    "\n",
    "#     V = np.zeros((n, max_iters + 1))\n",
    "#     H = np.zeros((max_iters + 1, max_iters))\n",
    "#     V[:, 0] = b\n",
    "\n",
    "#     for j in range(max_iters):\n",
    "#         w = A @ V[:, j]\n",
    "        \n",
    "#         for i in range(j + 1):\n",
    "#             # H[i, j] = np.dot(V[:, i], w)\n",
    "#             H[i, j] = V[:, i].conj().T @ w\n",
    "#             w = w - H[i, j] * V[:, i]\n",
    "        \n",
    "#         H[j + 1, j] = np.linalg.norm(w)\n",
    "\n",
    "        \n",
    "#         V[:, j + 1] = w / H[j + 1, j]\n",
    "        \n",
    "#         # Compute eigenvalues of the current H (top-left (j+1)x(j+1) block)\n",
    "#         eigvals = np.linalg.eigvals(H[:j+1, :j+1])\n",
    "#         lambda_max = eigvals[np.argmax(np.abs(eigvals))]\n",
    "\n",
    "#         # Optional early convergence check (change in largest Ritz value)\n",
    "#         if j > 0:\n",
    "#             delta = abs(lambda_max - prev_lambda)\n",
    "#             if delta < tol:\n",
    "#                 break\n",
    "#         prev_lambda = lambda_max\n",
    "    \n",
    "#     print(\"Number of iterations / max_iters:\", j + 1 , \"/\", max_iters)\n",
    "\n",
    "#     return lambda_max\n",
    "\n",
    "\n",
    "# A = np.random.randn(res_dim, res_dim)\n",
    "# tol=1e-12\n",
    "# max_iters=100\n",
    "# seed=0\n",
    "# print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_np(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "# print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73435d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi): 3.443780942023299\n",
      "max eigenvalue (check): 3.443780942023293\n"
     ]
    }
   ],
   "source": [
    "### naive jax version without lax primitives\n",
    "def max_eig_arnoldi_jax(A, tol=1e-12, max_iters=1000, seed=0):\n",
    "    n = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    b = jax.random.uniform(key, shape=(n,))\n",
    "    b = b / jnp.linalg.norm(b)\n",
    "\n",
    "    V = jnp.zeros((n, max_iters + 1))\n",
    "    H = jnp.zeros((max_iters + 1, max_iters))\n",
    "    V = V.at[:, 0].set(b)\n",
    "\n",
    "    lambda_max = 3\n",
    "\n",
    "    for j in range(max_iters):\n",
    "        w = A @ V[:, j]\n",
    "        \n",
    "        for i in range(j + 1):\n",
    "            H = H.at[i, j].set(V[:, i].conj().T @ w)\n",
    "            w = w - H[i, j] * V[:, i]\n",
    "        \n",
    "        H = H.at[j + 1, j].set(jnp.linalg.norm(w))\n",
    "        if H[j + 1, j] < tol:\n",
    "            break\n",
    "\n",
    "        V = V.at[:, j + 1].set(w / H[j + 1, j])\n",
    "        \n",
    "        # Compute eigenvalues of the current H (top-left (j+1)x(j+1) block)\n",
    "        eigvals = jnp.linalg.eigvals(H[:j+1, :j+1])\n",
    "        lambda_max = eigvals[jnp.argmax(jnp.abs(eigvals))]\n",
    "\n",
    "        # Optional early convergence check (change in largest Ritz value)\n",
    "        if j > 0:\n",
    "            delta = abs(lambda_max - prev_lambda)\n",
    "            if delta < tol:\n",
    "                break\n",
    "        prev_lambda = lambda_max\n",
    "\n",
    "    return lambda_max\n",
    "\n",
    "\n",
    "# A = np.random.randn(res_dim, res_dim)\n",
    "A = jax.random.normal(key, shape=(res_dim, res_dim))\n",
    "tol=1e-16\n",
    "max_iters=100\n",
    "seed=0\n",
    "print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_jax(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584ddc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi): 3.443780942023302\n",
      "max eigenvalue (check): 3.443780942023293\n"
     ]
    }
   ],
   "source": [
    "@functools.partial(jax.jit, static_argnames=[\"max_iters\"])\n",
    "def max_eig_arnoldi_lax(A, tol=1e-12, max_iters=100, seed=0):\n",
    "    '''\n",
    "    Perform Arnoldi iteration to find the largest eigenvalue of a matrix A. \n",
    "\n",
    "    Args:\n",
    "        A: The input matrix (n x n).\n",
    "        tol: Tolerance for convergence.\n",
    "        max_iters: Maximum number of iterations.\n",
    "        seed: Random seed for initialization.\n",
    "    Returns:\n",
    "        The largest eigenvalue of A.\n",
    "    '''\n",
    "    n = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    v0 = jax.random.normal(key, (n,))\n",
    "    v0 = v0 / jnp.linalg.norm(v0) # initial guess\n",
    "\n",
    "    V = jnp.zeros((n, max_iters + 1)) # orthogonal krylov basis\n",
    "    H = jnp.zeros((max_iters + 1, max_iters)) # hessnian matrix\n",
    "    V = V.at[:, 0].set(v0)\n",
    "\n",
    "    def body(carry):\n",
    "        j, V, H, prev_lam, done = carry\n",
    "        w = A @ V[:, j]\n",
    "\n",
    "        # Gram–Schmidt\n",
    "        def gs_step(i, val):\n",
    "            w, H = val\n",
    "            h = jnp.vdot(V[:, i], w)\n",
    "            H = H.at[i, j].set(h)\n",
    "            w = w - h * V[:, i]\n",
    "            return (w, H)\n",
    "        w, H = jax.lax.fori_loop(0, j + 1, gs_step, (w, H))\n",
    "\n",
    "        h_next = jnp.linalg.norm(w)\n",
    "        H = H.at[j + 1, j].set(h_next)\n",
    "        V = V.at[:, j + 1].set(jnp.where(h_next > 0, w / h_next, V[:, j + 1]))\n",
    "        eigvals = jnp.linalg.eigvals(H[:-1, :])     # now square & static\n",
    "        lam_max = eigvals[jnp.argmax(jnp.abs(eigvals))]\n",
    "\n",
    "        done = jnp.logical_or(done, jnp.abs(lam_max - prev_lam) < tol) # not actually used\n",
    "        return (j + 1, V, H, lam_max, done)\n",
    "\n",
    "    # check against max_iters\n",
    "    def cond(carry):\n",
    "        j, _, _, _, _ = carry\n",
    "        return j < max_iters\n",
    "\n",
    "    init_state = (0, V, H, 0.0 + 0j, False)\n",
    "    _, _, _, lambda_max, _ = jax.lax.while_loop(cond, body, init_state)\n",
    "    return lambda_max\n",
    "\n",
    "\n",
    "A = jax.random.normal(key, shape=(res_dim, res_dim))\n",
    "tol=1e-16\n",
    "max_iters=100\n",
    "seed=0\n",
    "print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_lax(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d271ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('max_iters',))\n",
    "def max_eig_arnoldi_lax_sparse(A, tol=1e-12, max_iters=300, seed=0):\n",
    "    \"\"\"\n",
    "    Arnoldi method optimized for sparse matrices\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed) \n",
    "    v0 = jax.random.normal(key, (n,))\n",
    "    v0 = v0 / jnp.linalg.norm(v0) # TODO with parallel / ensemble initialize with prev eigenvector\n",
    "    \n",
    "    # Pre-allocate arrays\n",
    "    V = jnp.zeros((n, max_iters + 1), dtype=A.dtype)\n",
    "    V = V.at[:, 0].set(v0)\n",
    "    H = jnp.zeros((max_iters, max_iters), dtype=A.dtype)\n",
    "    \n",
    "    \n",
    "    def arnoldi_step(carry):\n",
    "        j, V, H, prev_ritz, converged = carry\n",
    "        \n",
    "        # w = Av\n",
    "        w = jax.experimental.sparse.bcoo_dot_general(A, V[:, j],  dimension_numbers=(((1,), (0,)), ((), ())))\n",
    "\n",
    "        # Modified Gram–Schmidt\n",
    "        def gs_body(i, inner):\n",
    "            w, H = inner\n",
    "            h_ij = jnp.vdot(V[:, i], w)\n",
    "            H = H.at[i, j].set(h_ij)\n",
    "            w = w - h_ij * V[:, i]\n",
    "            return (w, H)\n",
    "\n",
    "        w, H = jax.lax.fori_loop(0, j + 1, gs_body, (w, H))\n",
    "        beta = jnp.linalg.norm(w)\n",
    "\n",
    "        # Write subdiag of hessenberg if matrix not full \n",
    "        H = jax.lax.cond(\n",
    "            (j + 1) < max_iters,\n",
    "            lambda args: args[0].at[args[1] + 1, args[1]].set(args[2]),\n",
    "            lambda args: args[0],\n",
    "            (H, j, beta)\n",
    "        )\n",
    "\n",
    "        # Normalise and append new basis vector\n",
    "        V = jax.lax.cond(\n",
    "            beta > 0,\n",
    "            lambda args: args[0].at[:, args[1] + 1].set(args[2] / args[3]),\n",
    "            lambda args: args[0],\n",
    "            (V, j, w, beta)\n",
    "        )\n",
    "\n",
    "        def get_max_eigenvalue(H, size):\n",
    "            \n",
    "            mask = jnp.arange(max_iters)[:, None] < size\n",
    "            mask = mask & (jnp.arange(max_iters)[None, :] < size)\n",
    "            \n",
    "            H_masked = jnp.where(mask, H, 0.0)\n",
    "            \n",
    "            all_eigvals = jnp.linalg.eigvals(H_masked)\n",
    "            \n",
    "            return all_eigvals[jnp.argmax(jnp.abs(all_eigvals))]\n",
    "        \n",
    "        lambda_max = get_max_eigenvalue(H, j+1)\n",
    "        \n",
    "        converged = (beta < tol) | ((j > 0) & (jnp.abs(lambda_max - prev_ritz) < tol))\n",
    "        \n",
    "        return (j + 1, V, H, lambda_max, converged)\n",
    "\n",
    "    def cond_fn(carry):\n",
    "        j, _, _, _, conv = carry\n",
    "        return (j < max_iters - 1) & (~conv)\n",
    "\n",
    "    init = (0, V, H, 0.0, False)\n",
    "    j_final, _, _, lambda_max, _ = jax.lax.while_loop(cond_fn, arnoldi_step, init)\n",
    "    \n",
    "    return lambda_max#, j_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3856c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi lax): 14.401025039437345\n",
      "max eigenvalue (check): 14.401025083145015\n"
     ]
    }
   ],
   "source": [
    "res_dim = 200\n",
    "A = jax.random.normal(key, (res_dim, res_dim))\n",
    "tol=1e-10\n",
    "max_iters=100\n",
    "seed=0\n",
    "\n",
    "out = np.abs(max_eig_arnoldi_lax(A, tol=tol, max_iters=max_iters, seed=seed))\n",
    "print(\"Max eigenvalue (arnoldi lax):\", out)\n",
    "# print(\"Number of iterations:\", out[1])\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7baa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wr(res_dim, density):\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    wrkey1, wrkey2 = jax.random.split(key)\n",
    "    N_nonzero = int(res_dim**2 * density)\n",
    "    wr_indices = jax.random.choice(\n",
    "        wrkey1,\n",
    "        res_dim**2,\n",
    "        shape=(N_nonzero,),\n",
    "    )\n",
    "    wr_vals = jax.random.uniform(\n",
    "        wrkey2, shape=N_nonzero, minval=-1, maxval=1\n",
    "    )\n",
    "    wr = jnp.zeros(res_dim * res_dim)\n",
    "    wr = wr.at[wr_indices].set(wr_vals)\n",
    "    wr = wr.reshape(res_dim, res_dim)\n",
    "    return wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679422bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken (dense eigvals): 0.8503098487854004\n",
      "Max eigenvalue (dense eigvals): 1.8291688631675567\n",
      "=============================================\n",
      "\n",
      "Time taken (dense naive): 32.61605787277222\n",
      "Max eigenvalue (dense naive): 1.829168894290524 \n",
      "\n",
      "Time taken (sparse naive): 17.40448546409607\n",
      "Max eigenvalue (sparse naive): 1.8291688942905129 \n",
      "\n",
      "Time taken (dense lax): 1.6839098930358887\n",
      "Max eigenvalue (dense lax): 1.8291688617096102 \n",
      "\n",
      "Time taken (sparse lax): 1.658437728881836\n",
      "Max eigenvalue (sparse lax): 1.829168861709604 \n",
      "\n",
      "Time taken (dense lax1): 3.0642952919006348\n",
      "Max eigenvalue (dense lax1): 1.829168834769205 \n",
      "\n",
      "Time taken (sparse lax1): 5.257415294647217\n",
      "Max eigenvalue (sparse lax1): 1.829168834769199 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_dim = 1000\n",
    "density = 0.01\n",
    "num_trials = 10  \n",
    "max_iters = 200 \n",
    "tol = 1e-16     \n",
    "seed = 0        \n",
    "\n",
    "wr_dense = create_wr(res_dim, density)\n",
    "wr_sparse = sparse.BCOO.fromdense(wr_dense)\n",
    "\n",
    "start_time = time.time()\n",
    "eig = jnp.max(jnp.abs(jnp.linalg.eigvals(wr_dense))).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense eigvals):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense eigvals):\", eig)\n",
    "print(\"=============================================\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_jax(wr_dense, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense naive):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense naive):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_jax(wr_sparse, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (sparse naive):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (sparse naive):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax(wr_dense, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense lax):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense lax):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax(wr_sparse, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (sparse lax):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (sparse lax):\", jnp.abs(eig), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac56f90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_trials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Timing jnp.linalg.eigvals (Dense) ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m times_dense_eigvals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_trials):\n\u001b[0;32m      4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m     _ \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmax(jnp\u001b[38;5;241m.\u001b[39mabs(jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvals(wr_dense)))\u001b[38;5;241m.\u001b[39mblock_until_ready()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_trials' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Timing jnp.linalg.eigvals (Dense) ---\n",
    "times_dense_eigvals = []\n",
    "for _ in range(num_trials):\n",
    "    start_time = time.time()\n",
    "    _ = jnp.max(jnp.abs(jnp.linalg.eigvals(wr_dense))).block_until_ready()\n",
    "    end_time = time.time()\n",
    "    times_dense_eigvals.append(end_time - start_time)\n",
    "avg_time_dense_eigvals = np.mean(times_dense_eigvals)\n",
    "print(f\"Average time taken (dense eigvals over {num_trials} trials): {avg_time_dense_eigvals:.6f} seconds\")\n",
    "print(\"=============================================\\n\")\n",
    "\n",
    "# --- Timing max_eig_arnoldi_jax (Dense) ---\n",
    "times_dense_naive = []\n",
    "for _ in range(num_trials):\n",
    "    start_time = time.time()\n",
    "    _ = max_eig_arnoldi_jax(wr_dense, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "    end_time = time.time()\n",
    "    times_dense_naive.append(end_time - start_time)\n",
    "avg_time_dense_naive = np.mean(times_dense_naive)\n",
    "print(f\"Average time taken (dense naive over {num_trials} trials): {avg_time_dense_naive:.6f} seconds\\n\")\n",
    "\n",
    "# --- Timing max_eig_arnoldi_jax (Sparse) ---\n",
    "times_sparse_naive = []\n",
    "for _ in range(num_trials):\n",
    "    start_time = time.time()\n",
    "    _ = max_eig_arnoldi_jax(wr_sparse, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "    end_time = time.time()\n",
    "    times_sparse_naive.append(end_time - start_time)\n",
    "avg_time_sparse_naive = np.mean(times_sparse_naive)\n",
    "print(f\"Average time taken (sparse naive over {num_trials} trials): {avg_time_sparse_naive:.6f} seconds\\n\")\n",
    "\n",
    "# --- Timing max_eig_arnoldi_lax (Dense) ---\n",
    "times_dense_lax = []\n",
    "for _ in range(num_trials):\n",
    "    start_time = time.time()\n",
    "    _ = max_eig_arnoldi_lax(wr_dense, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "    end_time = time.time()\n",
    "    times_dense_lax.append(end_time - start_time)\n",
    "avg_time_dense_lax = np.mean(times_dense_lax)\n",
    "print(f\"Average time taken (dense lax over {num_trials} trials): {avg_time_dense_lax:.6f} seconds\\n\")\n",
    "\n",
    "# --- Timing max_eig_arnoldi_lax (Sparse) ---\n",
    "times_sparse_lax = []\n",
    "for _ in range(num_trials):\n",
    "    start_time = time.time()\n",
    "    _ = max_eig_arnoldi_lax(wr_sparse, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "    end_time = time.time()\n",
    "    times_sparse_lax.append(end_time - start_time)\n",
    "avg_time_sparse_lax = np.mean(times_sparse_lax)\n",
    "print(f\"Average time taken (sparse lax over {num_trials} trials): {avg_time_sparse_lax:.6f} seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
