{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345ba182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"True\"\n",
    "# os.environ[\"JAX_DISABLE_JIT\"] = \"True\"\n",
    "# os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import sparse\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e173b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dim = 10\n",
    "key = jax.random.PRNGKey(0)\n",
    "density = 0.5\n",
    "wrkey1, wrkey2 = jax.random.split(key)\n",
    "spec_rad = 0.8\n",
    "\n",
    "N_nonzero = int(res_dim**2 * density)\n",
    "wr_indices = jax.random.choice(\n",
    "    wrkey1,\n",
    "    res_dim**2,\n",
    "    shape=(N_nonzero,),\n",
    ")\n",
    "wr_vals = jax.random.uniform(\n",
    "    wrkey2, shape=N_nonzero, minval=-1, maxval=1\n",
    ")\n",
    "wr = jnp.zeros(res_dim * res_dim)\n",
    "wr = wr.at[wr_indices].set(wr_vals)\n",
    "wr = wr.reshape(res_dim, res_dim)\n",
    "wr_dense = wr * (spec_rad / jnp.max(jnp.abs(jnp.linalg.eigvals(wr))))\n",
    "wr_sparse = sparse.BCOO.fromdense(wr_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a0d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def max_eig_arnoldi_np(A, tol=1e-12, max_iters=1000, seed=0):\n",
    "#     n = A.shape[0]\n",
    "#     np.random.seed(seed)\n",
    "#     b = np.random.rand(n)\n",
    "#     b = b / np.linalg.norm(b)\n",
    "\n",
    "#     V = np.zeros((n, max_iters + 1))\n",
    "#     H = np.zeros((max_iters + 1, max_iters))\n",
    "#     V[:, 0] = b\n",
    "\n",
    "#     for j in range(max_iters):\n",
    "#         w = A @ V[:, j]\n",
    "        \n",
    "#         for i in range(j + 1):\n",
    "#             # H[i, j] = np.dot(V[:, i], w)\n",
    "#             H[i, j] = V[:, i].conj().T @ w\n",
    "#             w = w - H[i, j] * V[:, i]\n",
    "        \n",
    "#         H[j + 1, j] = np.linalg.norm(w)\n",
    "\n",
    "        \n",
    "#         V[:, j + 1] = w / H[j + 1, j]\n",
    "        \n",
    "#         # Compute eigenvalues of the current H (top-left (j+1)x(j+1) block)\n",
    "#         eigvals = np.linalg.eigvals(H[:j+1, :j+1])\n",
    "#         lambda_max = eigvals[np.argmax(np.abs(eigvals))]\n",
    "\n",
    "#         # Optional early convergence check (change in largest Ritz value)\n",
    "#         if j > 0:\n",
    "#             delta = abs(lambda_max - prev_lambda)\n",
    "#             if delta < tol:\n",
    "#                 break\n",
    "#         prev_lambda = lambda_max\n",
    "    \n",
    "#     print(\"Number of iterations / max_iters:\", j + 1 , \"/\", max_iters)\n",
    "\n",
    "#     return lambda_max\n",
    "\n",
    "\n",
    "# A = np.random.randn(res_dim, res_dim)\n",
    "# tol=1e-12\n",
    "# max_iters=100\n",
    "# seed=0\n",
    "# print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_np(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "# print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73435d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi): 3.443780942023299\n",
      "max eigenvalue (check): 3.443780942023293\n"
     ]
    }
   ],
   "source": [
    "### naive jax version without lax primitives\n",
    "def max_eig_arnoldi_jax(A, tol=1e-12, max_iters=1000, seed=0):\n",
    "    n = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    b = jax.random.uniform(key, shape=(n,))\n",
    "    b = b / jnp.linalg.norm(b)\n",
    "\n",
    "    V = jnp.zeros((n, max_iters + 1))\n",
    "    H = jnp.zeros((max_iters + 1, max_iters))\n",
    "    V = V.at[:, 0].set(b)\n",
    "\n",
    "    lambda_max = 3\n",
    "\n",
    "    for j in range(max_iters):\n",
    "        w = A @ V[:, j]\n",
    "        \n",
    "        for i in range(j + 1):\n",
    "            H = H.at[i, j].set(V[:, i].conj().T @ w)\n",
    "            w = w - H[i, j] * V[:, i]\n",
    "        \n",
    "        H = H.at[j + 1, j].set(jnp.linalg.norm(w))\n",
    "        if H[j + 1, j] < tol:\n",
    "            break\n",
    "\n",
    "        V = V.at[:, j + 1].set(w / H[j + 1, j])\n",
    "        \n",
    "        # Compute eigenvalues of the current H (top-left (j+1)x(j+1) block)\n",
    "        eigvals = jnp.linalg.eigvals(H[:j+1, :j+1])\n",
    "        lambda_max = eigvals[jnp.argmax(jnp.abs(eigvals))]\n",
    "\n",
    "        # Optional early convergence check (change in largest Ritz value)\n",
    "        if j > 0:\n",
    "            delta = abs(lambda_max - prev_lambda)\n",
    "            if delta < tol:\n",
    "                break\n",
    "        prev_lambda = lambda_max\n",
    "\n",
    "    return lambda_max\n",
    "\n",
    "\n",
    "# A = np.random.randn(res_dim, res_dim)\n",
    "A = jax.random.normal(key, shape=(res_dim, res_dim))\n",
    "tol=1e-16\n",
    "max_iters=100\n",
    "seed=0\n",
    "print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_jax(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584ddc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi): 3.443780942023302\n",
      "max eigenvalue (check): 3.443780942023293\n"
     ]
    }
   ],
   "source": [
    "import functools, jax, jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"max_iters\"])\n",
    "def max_eig_arnoldi_lax1(A, tol=1e-12, max_iters=1000, seed=0):\n",
    "    n   = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    v0  = jax.random.normal(key, (n,))\n",
    "    v0  = v0 / jnp.linalg.norm(v0)\n",
    "\n",
    "    V = jnp.zeros((n, max_iters + 1))\n",
    "    H = jnp.zeros((max_iters + 1, max_iters))      # rectangular\n",
    "    V = V.at[:, 0].set(v0)\n",
    "\n",
    "    def body(carry):\n",
    "        j, V, H, prev_lam, done = carry\n",
    "        w = A @ V[:, j]\n",
    "\n",
    "        # Gram–Schmidt\n",
    "        def gs_step(i, val):\n",
    "            w, H = val\n",
    "            h = jnp.vdot(V[:, i], w)\n",
    "            H = H.at[i, j].set(h)\n",
    "            w = w - h * V[:, i]\n",
    "            return (w, H)\n",
    "        w, H = lax.fori_loop(0, j + 1, gs_step, (w, H))\n",
    "\n",
    "        h_next = jnp.linalg.norm(w)\n",
    "        H = H.at[j + 1, j].set(h_next)\n",
    "        V = V.at[:, j + 1].set(jnp.where(h_next > 0, w / h_next, V[:, j + 1]))\n",
    "        # ‹★› use the square upper block (shape max_iters × max_iters)\n",
    "        eigvals = jnp.linalg.eigvals(H[:-1, :])     # now square & static\n",
    "        lam_max = eigvals[jnp.argmax(jnp.abs(eigvals))]\n",
    "\n",
    "        done = jnp.logical_or(done, jnp.abs(lam_max - prev_lam) < tol)\n",
    "        return (j + 1, V, H, lam_max, done)\n",
    "\n",
    "    def cond(carry):\n",
    "        j, *_ = carry\n",
    "        return j < max_iters\n",
    "\n",
    "    init_state = (0, V, H, 0.0 + 0j, False)\n",
    "    _, _, _, lambda_max, _ = lax.while_loop(cond, body, init_state)\n",
    "    return lambda_max\n",
    "\n",
    "\n",
    "A = jax.random.normal(key, shape=(res_dim, res_dim))\n",
    "tol=1e-16\n",
    "max_iters=100\n",
    "seed=0\n",
    "print(\"Max eigenvalue (arnoldi):\", np.abs(max_eig_arnoldi_lax1(A, tol=tol, max_iters=max_iters, seed=seed)))\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d271ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.experimental\n",
    "import jax.experimental.sparse\n",
    "import jax.numpy as jnp\n",
    "from jax import random, lax\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('max_iters',))\n",
    "def max_eig_arnoldi_lax(A, *, tol=1e-12, max_iters=300, seed=0):\n",
    "    \"\"\"\n",
    "    Arnoldi method optimized for sparse matrices (JAX sparse.BCOO format)\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    v0 = jax.random.normal(key, (n,))\n",
    "    v0 = v0 / jnp.linalg.norm(v0)\n",
    "    \n",
    "    # Pre-allocate arrays with correct types\n",
    "    V = jnp.zeros((n, max_iters + 1), dtype=A.dtype)\n",
    "    V = V.at[:, 0].set(v0)\n",
    "    H = jnp.zeros((max_iters, max_iters), dtype=A.dtype)\n",
    "    \n",
    "    # Check if A is a sparse matrix\n",
    "    is_sparse = True#isinstance(A, sparse.BCOO)\n",
    "    \n",
    "    def arnoldi_step(carry):\n",
    "        j, V, H, prev_ritz, converged = carry\n",
    "        \n",
    "        # Use the appropriate matrix-vector product based on type\n",
    "        if is_sparse:\n",
    "        # w = A.coo_matvec(V[:, j])\n",
    "            w = jax.experimental.sparse.bcoo_dot_general(A, V[:, j],  dimension_numbers=(((1,), (0,)), ((), ())))\n",
    "        else:\n",
    "            w = A @ V[:, j]\n",
    "\n",
    "        # Modified Gram–Schmidt\n",
    "        def gs_body(i, inner):\n",
    "            w, H = inner\n",
    "            h_ij = jnp.vdot(V[:, i], w)\n",
    "            H = H.at[i, j].set(h_ij)\n",
    "            w = w - h_ij * V[:, i]\n",
    "            return (w, H)\n",
    "\n",
    "        w, H = lax.fori_loop(0, j + 1, gs_body, (w, H))\n",
    "        beta = jnp.linalg.norm(w)\n",
    "\n",
    "        # Safely write the sub‑diagonal if we haven't filled the matrix\n",
    "        H = lax.cond(\n",
    "            (j + 1) < max_iters,\n",
    "            lambda args: args[0].at[args[1] + 1, args[1]].set(args[2]),\n",
    "            lambda args: args[0],\n",
    "            (H, j, beta)\n",
    "        )\n",
    "\n",
    "        # Normalise and append new basis vector\n",
    "        V = lax.cond(\n",
    "            beta > 0,\n",
    "            lambda args: args[0].at[:, args[1] + 1].set(args[2] / args[3]),\n",
    "            lambda args: args[0],\n",
    "            (V, j, w, beta)\n",
    "        )\n",
    "\n",
    "        # KEY CHANGE: Use custom eigenvalue computation with masking\n",
    "        # Instead of H[:j+1, :j+1] which causes dynamic slicing error\n",
    "        def get_max_eigenvalue(H, size):\n",
    "            # Create a mask for the active submatrix\n",
    "            mask = jnp.arange(max_iters)[:, None] < size\n",
    "            mask = mask & (jnp.arange(max_iters)[None, :] < size)\n",
    "            \n",
    "            # Create a masked copy (zeros outside the j×j submatrix)\n",
    "            H_masked = jnp.where(mask, H, 0.0)\n",
    "            \n",
    "            # Compute eigenvalues of the full matrix (most will be 0)\n",
    "            all_eigvals = jnp.linalg.eigvals(H_masked)\n",
    "            \n",
    "            # Return the one with largest magnitude\n",
    "            return all_eigvals[jnp.argmax(jnp.abs(all_eigvals))]\n",
    "        \n",
    "        lambda_max = get_max_eigenvalue(H, j+1)\n",
    "        \n",
    "        # Convergence tests\n",
    "        converged = (beta < tol) | ((j > 0) & (jnp.abs(lambda_max - prev_ritz) < tol))\n",
    "        \n",
    "        return (j + 1, V, H, lambda_max, converged)\n",
    "\n",
    "    def cond_fn(carry):\n",
    "        j, _, _, _, conv = carry\n",
    "        return (j < max_iters - 1) & (~conv)\n",
    "\n",
    "    init = (0, V, H, 0.0, False)\n",
    "    j_final, _, _, lambda_max, _ = lax.while_loop(cond_fn, arnoldi_step, init)\n",
    "    \n",
    "    return lambda_max#, j_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3856c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max eigenvalue (arnoldi lax): 14.401025039437345\n",
      "max eigenvalue (check): 14.401025083145015\n"
     ]
    }
   ],
   "source": [
    "res_dim = 200\n",
    "A = jax.random.normal(key, (res_dim, res_dim))\n",
    "tol=1e-10\n",
    "max_iters=100\n",
    "seed=0\n",
    "\n",
    "out = np.abs(max_eig_arnoldi_lax(A, tol=tol, max_iters=max_iters, seed=seed))\n",
    "print(\"Max eigenvalue (arnoldi lax):\", out)\n",
    "# print(\"Number of iterations:\", out[1])\n",
    "print(\"max eigenvalue (check):\", np.max(np.abs(np.linalg.eigvals(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7baa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wr(res_dim, density):\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    wrkey1, wrkey2 = jax.random.split(key)\n",
    "    N_nonzero = int(res_dim**2 * density)\n",
    "    wr_indices = jax.random.choice(\n",
    "        wrkey1,\n",
    "        res_dim**2,\n",
    "        shape=(N_nonzero,),\n",
    "    )\n",
    "    wr_vals = jax.random.uniform(\n",
    "        wrkey2, shape=N_nonzero, minval=-1, maxval=1\n",
    "    )\n",
    "    wr = jnp.zeros(res_dim * res_dim)\n",
    "    wr = wr.at[wr_indices].set(wr_vals)\n",
    "    wr = wr.reshape(res_dim, res_dim)\n",
    "    return wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679422bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken (dense eigvals): 3.250822067260742\n",
      "Max eigenvalue (dense eigvals): 5.766258653353951\n",
      "=============================================\n",
      "\n",
      "Time taken (dense naive): 10.997761964797974\n",
      "Max eigenvalue (dense naive): 5.7254152264007105 \n",
      "\n",
      "Time taken (sparse naive): 4.024555683135986\n",
      "Max eigenvalue (sparse naive): 5.725415226400742 \n",
      "\n",
      "Time taken (dense lax): 0.44333767890930176\n",
      "Max eigenvalue (dense lax): 5.758381695577947 \n",
      "\n",
      "Time taken (sparse lax): 0.4044039249420166\n",
      "Max eigenvalue (sparse lax): 5.7583816955779605 \n",
      "\n",
      "Time taken (dense lax1): 0.48555850982666016\n",
      "Max eigenvalue (dense lax1): 5.755736557235635 \n",
      "\n",
      "Time taken (sparse lax1): 0.4642350673675537\n",
      "Max eigenvalue (sparse lax1): 5.755736557235636 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_dim = 2000\n",
    "density = 0.05\n",
    "\n",
    "wr_dense = create_wr(res_dim, density)\n",
    "wr_sparse = sparse.BCOO.fromdense(wr_dense)\n",
    "\n",
    "start_time = time.time()\n",
    "eig = jnp.max(jnp.abs(jnp.linalg.eigvals(wr_dense))).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense eigvals):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense eigvals):\", eig)\n",
    "print(\"=============================================\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_jax(wr_dense, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense naive):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense naive):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_jax(wr_sparse, tol=1e-16, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (sparse naive):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (sparse naive):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax(wr_dense, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense lax):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense lax):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax(wr_sparse, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (sparse lax):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (sparse lax):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax1(wr_dense, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (dense lax1):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (dense lax1):\", jnp.abs(eig), \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "eig = max_eig_arnoldi_lax1(wr_sparse, tol=tol, max_iters=max_iters, seed=seed).block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"Time taken (sparse lax1):\", end_time - start_time)\n",
    "print(\"Max eigenvalue (sparse lax1):\", jnp.abs(eig), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb121922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def max_eigval_power_iteration(A, seed=0, tol = 1e-12, max_iters=2000):\n",
    "#     key = jax.random.PRNGKey(seed)\n",
    "#     b_k = jax.random.normal(key, shape=(A.shape[0],)) \n",
    "#     b_k = b_k / jnp.linalg.norm(b_k)\n",
    "\n",
    "#     def continue_iteration(params):\n",
    "#         b_k, b_k_prev, iter_count = params\n",
    "#         return jnp.logical_and(jnp.linalg.norm(b_k - b_k_prev) > tol, iter_count <= max_iters)\n",
    "    \n",
    "#     def power_iteration_step(params):\n",
    "#         b_k, _, iter_count = params\n",
    "#         b_k_next = A @ b_k\n",
    "#         b_k_next = b_k_next / jnp.linalg.norm(b_k_next) \n",
    "#         iter_count += 1\n",
    "#         return (b_k_next, b_k, iter_count)\n",
    "\n",
    "#     out = jax.lax.while_loop(continue_iteration,power_iteration_step,(b_k, b_k+1, 0))\n",
    "#     b_k_final, num_iters = out[0], out[2]\n",
    "#     print(\"Number of iterations / total iters: \", num_iters-1, \"/\", max_iters)\n",
    "#     max_eigval = jnp.dot(b_k_final.T, A @ b_k_final) / jnp.dot(b_k_final.T, b_k_final) # Rayleigh quotient\n",
    "#     return max_eigval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf68fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test it out \n",
    "# wr_dense = create_wr(200, 0.02)\n",
    "# wr_sparse = sparse.BCOO.fromdense(wr_dense)\n",
    "# iters = 1000\n",
    "\n",
    "# print(\"Max eigval from jnp.linalg.eigvals: \", jnp.max(jnp.linalg.eigvals(wr_dense)))\n",
    "# print(\"Max eigval from power iteration: \", max_eigval_power_iteration(wr_dense,max_iters=10000, tol = 1e-10))\n",
    "# print(\"Max eigval from sparse power iteration: \", max_eigval_power_iteration(wr_sparse,max_iters=10000, tol = 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb900de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def max_eigval_arnoldi(A, seed=0, tol = 1e-12, max_iters=2000):\n",
    "#     key = jax.random.PRNGKey(seed)\n",
    "#     b_k = jax.random.normal(key, shape=(A.shape[0],)) \n",
    "#     b_k = b_k / jnp.linalg.norm(b_k)\n",
    "\n",
    "#     def continue_iteration(params):\n",
    "#         b_k, b_k_prev, iter_count = params\n",
    "#         return jnp.logical_and(jnp.linalg.norm(b_k - b_k_prev) > tol, iter_count <= max_iters)\n",
    "    \n",
    "#     def arnoldi_step(params):\n",
    "#         b_k, _, iter_count = params\n",
    "#         b_k_next = A @ b_k\n",
    "#         b_k_next = b_k_next / jnp.linalg.norm(b_k_next) \n",
    "#         iter_count += 1\n",
    "#         return (b_k_next, b_k, iter_count)\n",
    "\n",
    "#     out = jax.lax.while_loop(continue_iteration,arnoldi_step,(b_k, b_k+1, 0))\n",
    "#     b_k_final, num_iters = out[0], out[2]\n",
    "#     print(\"Number of iterations / total iters: \", num_iters-1, \"/\", max_iters)\n",
    "#     max_eigval = jnp.dot(b_k_final.T, A @ b_k_final) / jnp.dot(b_k_final.T, b_k_final) # Rayleigh quotient\n",
    "#     return max_eigval\n",
    "\n",
    "# # test it out\n",
    "# wr_dense = create_wr(200, 0.02)\n",
    "# wr_sparse = sparse.BCOO.fromdense(wr_dense)\n",
    "# iters = 1000\n",
    "# print(\"Max eigval from jnp.linalg.eigvals: \", jnp.max(jnp.linalg.eigvals(wr_dense)))\n",
    "# print(\"Max eigval from arnoldi: \", max_eigval_arnoldi(wr_dense,max_iters=10000, tol = 1e-10))\n",
    "# print(\"Max eigval from sparse arnoldi: \", max_eigval_arnoldi(wr_sparse,max_iters=10000, tol = 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84c638",
   "metadata": {},
   "source": [
    "# Timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e9c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dims = jnp.arange(100, 1001, 100)\n",
    "# densities = jnp.arange(0.01, 0.21, 0.01)\n",
    "res_dims = [100, 200, 300]\n",
    "densities = [0.01, 0.05]\n",
    "num_trials = 10\n",
    "results = jnp.zeros((len(res_dims), len(densities), num_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa39ea8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_eigval_power_iteration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m wr \u001b[38;5;241m=\u001b[39m create_wr(res_dim, density)\n\u001b[0;32m      6\u001b[0m start_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m _ \u001b[38;5;241m=\u001b[39m max_eigval_power_iteration(wr)\u001b[38;5;241m.\u001b[39mblock_until_ready()\n\u001b[0;32m      8\u001b[0m end_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mat[i, j, k]\u001b[38;5;241m.\u001b[39mset(end_t \u001b[38;5;241m-\u001b[39m start_t)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_eigval_power_iteration' is not defined"
     ]
    }
   ],
   "source": [
    "### Dense arnoldi\n",
    "for i, res_dim in enumerate(res_dims):\n",
    "    for j, density in enumerate(densities):\n",
    "        for k in range(num_trials):\n",
    "            wr = create_wr(res_dim, density)\n",
    "            start_t = time.time()\n",
    "            _ = max_eigval_power_iteration(wr).block_until_ready()\n",
    "            end_t = time.time()\n",
    "            results = results.at[i, j, k].set(end_t - start_t)\n",
    "\n",
    "# average out the trials\n",
    "avg_results_dense_pi = jnp.mean(results, axis=2)\n",
    "std_results_dense_pi = jnp.std(results, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sparse power iteration\n",
    "for i, res_dim in enumerate(res_dims):\n",
    "    for j, density in enumerate(densities):\n",
    "        for k in range(num_trials):\n",
    "            wr = create_wr(res_dim, density)\n",
    "            wr_sparse = sparse.BCOO.fromdense(wr)\n",
    "            start_t = time.time()\n",
    "            _ = max_eigval_power_iteration(wr_sparse).block_until_ready()\n",
    "            end_t = time.time()\n",
    "            results = results.at[i, j, k].set(end_t - start_t)\n",
    "\n",
    "# average out the trials\n",
    "avg_results_sparse_pi = jnp.mean(results, axis=2)\n",
    "std_results_sparse_pi = jnp.std(results, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45666fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dense jnp.linalg.eigvals\n",
    "for i, res_dim in enumerate(res_dims):\n",
    "    for j, density in enumerate(densities):\n",
    "        for k in range(num_trials):\n",
    "            wr = create_wr(res_dim, density)\n",
    "            start_t = time.time()\n",
    "            _ = jnp.max(jnp.linalg.eigvals(wr)).block_until_ready()\n",
    "            end_t = time.time()\n",
    "            results = results.at[i, j, k].set(end_t - start_t)\n",
    "\n",
    "# average out the trials\n",
    "avg_results_dense_eig = jnp.mean(results, axis=2)\n",
    "std_results_dense_eig = jnp.std(results, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bce45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
